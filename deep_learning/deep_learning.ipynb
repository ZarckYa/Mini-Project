{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e66fc961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "015e5273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complex.id</th>\n",
       "      <th>gene</th>\n",
       "      <th>cdr3</th>\n",
       "      <th>v.segm</th>\n",
       "      <th>j.segm</th>\n",
       "      <th>species</th>\n",
       "      <th>mhc.a</th>\n",
       "      <th>mhc.b</th>\n",
       "      <th>mhc.class</th>\n",
       "      <th>antigen.epitope</th>\n",
       "      <th>antigen.gene</th>\n",
       "      <th>antigen.species</th>\n",
       "      <th>vdjdb.score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TRA</td>\n",
       "      <td>CIVRAPGRADMRF</td>\n",
       "      <td>TRAV26-1*01</td>\n",
       "      <td>TRAJ43*01</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>HLA-B*08</td>\n",
       "      <td>B2M</td>\n",
       "      <td>MHCI</td>\n",
       "      <td>FLKEKGGL</td>\n",
       "      <td>Nef</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TRB</td>\n",
       "      <td>CASSYLPGQGDHYSNQPQHF</td>\n",
       "      <td>TRBV13*01</td>\n",
       "      <td>TRBJ1-5*01</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>HLA-B*08</td>\n",
       "      <td>B2M</td>\n",
       "      <td>MHCI</td>\n",
       "      <td>FLKEKGGL</td>\n",
       "      <td>Nef</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>TRB</td>\n",
       "      <td>CASSFEAGQGFFSNQPQHF</td>\n",
       "      <td>TRBV13*01</td>\n",
       "      <td>TRBJ1-5*01</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>HLA-B*08</td>\n",
       "      <td>B2M</td>\n",
       "      <td>MHCI</td>\n",
       "      <td>FLKEKGGL</td>\n",
       "      <td>Nef</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>TRA</td>\n",
       "      <td>CAVPSGAGSYQLTF</td>\n",
       "      <td>TRAV20*01</td>\n",
       "      <td>TRAJ28*01</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>HLA-B*08</td>\n",
       "      <td>B2M</td>\n",
       "      <td>MHCI</td>\n",
       "      <td>FLKEKGGL</td>\n",
       "      <td>Nef</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>TRB</td>\n",
       "      <td>CASSFEPGQGFYSNQPQHF</td>\n",
       "      <td>TRBV13*01</td>\n",
       "      <td>TRBJ1-5*01</td>\n",
       "      <td>HomoSapiens</td>\n",
       "      <td>HLA-B*08</td>\n",
       "      <td>B2M</td>\n",
       "      <td>MHCI</td>\n",
       "      <td>FLKEKGGL</td>\n",
       "      <td>Nef</td>\n",
       "      <td>HIV-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   complex.id gene                  cdr3       v.segm      j.segm  \\\n",
       "0           1  TRA         CIVRAPGRADMRF  TRAV26-1*01   TRAJ43*01   \n",
       "1           1  TRB  CASSYLPGQGDHYSNQPQHF    TRBV13*01  TRBJ1-5*01   \n",
       "2           0  TRB   CASSFEAGQGFFSNQPQHF    TRBV13*01  TRBJ1-5*01   \n",
       "3           2  TRA        CAVPSGAGSYQLTF    TRAV20*01   TRAJ28*01   \n",
       "4           2  TRB   CASSFEPGQGFYSNQPQHF    TRBV13*01  TRBJ1-5*01   \n",
       "\n",
       "       species     mhc.a mhc.b mhc.class antigen.epitope antigen.gene  \\\n",
       "0  HomoSapiens  HLA-B*08   B2M      MHCI        FLKEKGGL          Nef   \n",
       "1  HomoSapiens  HLA-B*08   B2M      MHCI        FLKEKGGL          Nef   \n",
       "2  HomoSapiens  HLA-B*08   B2M      MHCI        FLKEKGGL          Nef   \n",
       "3  HomoSapiens  HLA-B*08   B2M      MHCI        FLKEKGGL          Nef   \n",
       "4  HomoSapiens  HLA-B*08   B2M      MHCI        FLKEKGGL          Nef   \n",
       "\n",
       "  antigen.species  vdjdb.score  \n",
       "0           HIV-1            2  \n",
       "1           HIV-1            2  \n",
       "2           HIV-1            2  \n",
       "3           HIV-1            2  \n",
       "4           HIV-1            2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. load vdj dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib\n",
    "vdjdb = pd.read_csv(\"../processed_data/vdjdb_preprocessd_nonull.txt\", sep = \"\\t\")\n",
    "vdjdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bac17db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary feature extraction return:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "DictVectorized feature names：\n",
      " ['cdr3=CAAAASGGSYIPTF' 'cdr3=CAAADEEIGNQPQHF' 'cdr3=CAAALNTNAGKSTF' ...\n",
      " 'v.segm=TRBV7-9*03' 'v.segm=TRBV9*01' 'v.segm=TRBV9*02']\n"
     ]
    }
   ],
   "source": [
    "data=vdjdb[['gene','cdr3','v.segm','j.segm','mhc.a','mhc.b']]\n",
    "target=vdjdb['antigen.epitope']\n",
    "# 3. feature engineering\n",
    "\n",
    "# 3.1 feature extraction\n",
    "\n",
    "# 1) Dictionary feature extraction\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "data=data.to_dict(orient=\"records\") \n",
    "DicVec_transfer = DictVectorizer(sparse=False)\n",
    "data = DicVec_transfer.fit_transform(data)\n",
    "print(\"Dictionary feature extraction return:\\n\", data)\n",
    "print(\"DictVectorized feature names：\\n\", DicVec_transfer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29d1a9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452\n"
     ]
    }
   ],
   "source": [
    "n_c=np.unique(target).shape[0]\n",
    "print(n_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d46fe737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "target2=vdjdb[['antigen.epitope']].to_dict(orient=\"records\") \n",
    "DicVec_transfer2 = DictVectorizer(sparse=False)\n",
    "target2 = DicVec_transfer2.fit_transform(target2)\n",
    "print(target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74cb42db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 16 16 ... 21 21 21]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "target2_Kmeans= cluster.KMeans(n_clusters = n_c, random_state = 42)\n",
    "target2_cluster_labels = target2_Kmeans.fit_predict(target2)\n",
    "print(target2_cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2dc3bbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452,)\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(target2_cluster_labels).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c994e387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:\n",
      " (8498, 7445)\n",
      "x_test:\n",
      " (2833, 7445)\n",
      "y_train:\n",
      " (8498,)\n",
      "y_test:\n",
      " (2833,)\n"
     ]
    }
   ],
   "source": [
    "# 2. split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target2_cluster_labels,\n",
    "random_state=22)\n",
    "print(\"x_train:\\n\", x_train.shape)\n",
    "print(\"x_test:\\n\", x_test.shape)\n",
    "print(\"y_train:\\n\", y_train.shape)\n",
    "print(\"y_test:\\n\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28f9d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "116fb577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62  0  6 ... 19  8 24]\n"
     ]
    }
   ],
   "source": [
    "#y_train = tf.cast(x_train, tf.float32)\n",
    "#y_test = tf.cast(x_test, tf.float32)\n",
    "#print(y_train.shape)\n",
    "#target2=target.to_dict(orient=\"records\") \n",
    "#DicVec_transfer2 = DictVectorizer(sparse=False)\n",
    "#target2 = DicVec_transfer2.fit_transform(target)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5dc90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "151505bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成神经网络的参数，输入层为7445个输入节点；故输出层为神经元个数为一共有多少种epitope\n",
    "# 用tf.Variable()标记参数可训练\n",
    "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
    "w1 = tf.Variable(tf.random.truncated_normal([7445, n_c], stddev=0.1, seed=1))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([n_c], stddev=0.1, seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37ede4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1  # 学习率为0.1\n",
    "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
    "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
    "epoch = 500  # 循环500轮\n",
    "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c252a38a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [32,3] vs. [32,452] [Op:Sub]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(y)  \u001b[38;5;66;03m# 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(y_train, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# 将标签值转换为独热码格式，方便计算loss和accuracy\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(\u001b[43my_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m))  \u001b[38;5;66;03m# 采用均方误差损失函数mse = mean(sum(y-out)^2)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     loss_all \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 计算loss对各个参数的梯度\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Programs\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mE:\\Programs\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [32,3] vs. [32,452] [Op:Sub]"
     ]
    }
   ],
   "source": [
    "# 训练部分\n",
    "for epoch in range(epoch):  #数据集级别的循环，每个epoch循环一次数据集\n",
    "    for step, (x_train, y_train) in enumerate(train_db):  #batch级别的循环 ，每个step循环一个batch\n",
    "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
    "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
    "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
    "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
    "        # 计算loss对各个参数的梯度\n",
    "        grads = tape.gradient(loss, [w1, b1])\n",
    "\n",
    "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad\n",
    "        w1.assign_sub(lr * grads[0])  # 参数w1自更新\n",
    "        b1.assign_sub(lr * grads[1])  # 参数b自更新\n",
    "\n",
    "    # 每个epoch，打印loss信息\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all/4))\n",
    "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
    "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
    "\n",
    "    # 测试部分\n",
    "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_db:\n",
    "        # 使用更新后的参数进行预测\n",
    "        y = tf.matmul(x_test, w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
    "        # 将pred转换为y_test的数据类型\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        # 将每个batch的correct数加起来\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        # 将所有batch中的correct数加起来\n",
    "        total_correct += int(correct)\n",
    "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
    "        total_number += x_test.shape[0]\n",
    "    # 总的准确率等于total_correct/total_number\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc)\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制 loss 曲线\n",
    "plt.title('Loss Function Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Loss')  # y轴变量名称\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend()  # 画出曲线图标\n",
    "plt.show()  # 画出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39be57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制 Accuracy 曲线\n",
    "plt.title('Acc Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Acc')  # y轴变量名称\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
